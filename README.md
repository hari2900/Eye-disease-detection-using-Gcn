# ğŸ‘ï¸ Eye Disease Detection using GCN and EfficientNet

A deep learning project that detects and classifies common eye diseasesâ€”**Cataract**, **Glaucoma**, **Diabetic Retinopathy**, and **Normal**â€”from retinal fundus images. This system combines **EfficientNet** for feature extraction and **Graph Convolutional Networks (GCNs)** for relational learning on image features, leveraging spatial dependencies between samples for improved diagnostic accuracy.Utilized graph-based relationships and spatial dependencies in image features, applied graph coarsening techniques, and achieved 94.69% accuracy with the base GCN model and 95.11% with the refined GCN architecture
---

## ğŸ“Œ Features

- EfficientNet-based deep feature extraction from fundus images.
- Graph construction using extracted features to capture similarity.
- GCN-based disease classification.
- Graph coarsening and refinement for optimized learning.
- Comparative performance analysis between base GCN and refined GCN.

---

## ğŸ—‚ï¸ Dataset

The model was trained and evaluated on a curated dataset containing labeled retinal images across 4 categories:

- **Cataract**
- **Glaucoma**
- **Diabetic Retinopathy**
- **Normal**

> ğŸ“ Note: "https://www.kaggle.com/datasets/gunavenkatdoddi/eye-diseases-classification"
---

## ğŸ—ï¸ Project Structure

```bash
Eye-Disease-Detection-GCN/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Original dataset (4 disease classes)
â”‚ â”‚ â”œâ”€â”€ diabetic_retinopathy/
â”‚ â”‚ â”œâ”€â”€ cataract/
â”‚ â”‚ â”œâ”€â”€ glaucoma/
â”‚ â”‚ â””â”€â”€ normal/
â”‚ â”œâ”€â”€ preprocessed/ # Preprocessed images
â”‚ â”‚ â”œâ”€â”€ diabetic_retinopathy/
â”‚ â”‚ â”œâ”€â”€ cataract/
â”‚ â”‚ â”œâ”€â”€ glaucoma/
â”‚ â”‚ â””â”€â”€ normal/
â”‚ â””â”€â”€ graph/ # Graph data (EfficientNet features, labels, edges)
â”‚ â”œâ”€â”€ features.npy
â”‚ â”œâ”€â”€ labels.npy
â”‚ â””â”€â”€ edge_index.npy
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ efficientnet_features.py # Extracts and saves features.npy and labels.npy
â”‚ â””â”€â”€ gcn_model.py # GCN architecture

---
```

---

## ğŸ“¦ Requirements

- Python 3.8+
- PyTorch
- PyTorch Geometric
- scikit-learn
- pandas
- numpy

Install dependencies:

```bash
pip install -r requirements.txt
```

---

## ğŸš€ How to Run

### 1. Preprocess and Load the Data

```bash
python utils/data_loader.py
```

### 2. Train the GCN Model

```bash
python train_gcn.py
```

### 3. Evaluate the Model

```bash
python evaluate_gcn.py
```

---

## ğŸ“Š Model Accuracy Comparison

| Model             | Train Accuracy | Test Accuracy | Test Loss |
|------------------|----------------|---------------|-----------|
| GCN Model         | 94.69%         | 93.01%        | 14.52     |
| Refined GCN Model | 95.11%         | 92.01%        | 13.90     |

---

## ğŸ“ˆ Classification Report

```python
from sklearn.metrics import classification_report

model.eval()
out = model(data.x, data.edge_index)
pred = out.argmax(dim=1).cpu()
print(classification_report(y.cpu(), pred, digits=3))
```

**Output:**

```
              precision    recall  f1-score   support

           0      0.966     0.960     0.963      1038
           1      0.997     0.994     0.995      1098
           2      0.917     0.887     0.902      1007
           3      0.902     0.939     0.920      1074

    accuracy                          0.946      4217
   macro avg      0.945     0.945     0.945      4217
weighted avg      0.946     0.946     0.946      4217
```

---

## âœ… Conclusion

- GCN models are effective in learning from structured image representations using graph data.
- The refined GCN architecture shows improved training performance, though it slightly overfits compared to the base model.
- Precision, recall, and F1-scores across all classes indicate robust and consistent model behavior.

---

## ğŸ§  Future Work

- ğŸ”¬ Explore deeper GCN layers and attention-based architectures like Graph Attention Networks (GAT).
- ğŸ“‰ Integrate end-to-end learning from raw images to final classification using hybrid models.
- ğŸ” Incorporate explainability using **Grad-CAM**, **Score-CAM**, **LRP**, or **SHAP** to visualize disease-relevant features.

---
